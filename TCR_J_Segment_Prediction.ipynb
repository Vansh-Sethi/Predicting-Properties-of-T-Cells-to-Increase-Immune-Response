{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCR_J_Segment_Prediction",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk90gwIdqHCV",
        "colab_type": "text"
      },
      "source": [
        "# Dependancies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuJnsCuUpz5u",
        "colab_type": "code",
        "outputId": "abf907c5-6d25-40ca-deab-17e10e900e1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import *\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LemCjz9CqR-M"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1p43UHwqUwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_data = \"/content/Full Database for TCRs.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tVftAIbq5mt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(path_to_data)\n",
        "data = data.dropna()\n",
        "data = data.reset_index(drop=True)\n",
        "\n",
        "data_epitope = data['Epitope'][:50001]\n",
        "data_v = data['V'][:50001]\n",
        "data_j = data['J'][:50001]\n",
        "data_cdr3 = data['CDR3'][:50001]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_xaxciTvv_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder_protien(data_frame):\n",
        "  encoder_dict = {'a':2,'b':3,'c':4,'d':5,'e':6,'f':7,'g':8,'h':9,'i':10,\n",
        "             'j':11,'k':12,'l':13,'m':14,'n':15,'o':16,'p':17,'q':18,'r':19,'s':20,\n",
        "             't':21,'u':22,'v':23,'w':24,'x':25,'y':26,'z':27,'=':28}\n",
        "\n",
        "  output = []\n",
        "  max_length = 0\n",
        "\n",
        "  for sequence in data_frame:\n",
        "    a = len(sequence)\n",
        "    if (a > max_length):\n",
        "      max_length = a+2\n",
        "\n",
        "  for sequence in data_frame:\n",
        "    sequence_temp = []\n",
        "\n",
        "    for protien in sequence:\n",
        "      sequence_temp.append(encoder_dict[protien.lower()])\n",
        "\n",
        "    for i in range(max_length-len(sequence_temp)):\n",
        "      sequence_temp.append(0)\n",
        "\n",
        "    output.append(sequence_temp)\n",
        "\n",
        "  output = np.asarray(output)\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jmi_hHuAoga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "unique_j = list(data_j.unique())\n",
        "\n",
        "Y_Train = []\n",
        "\n",
        "for i in data_j:\n",
        "  temp = []\n",
        "  Y_Train.append(unique_j.index(i))\n",
        "\n",
        "Y_Train = to_categorical(Y_Train)\n",
        "\n",
        "Y_Train = np.asarray(Y_Train)\n",
        "X_Train = encoder_protien(data_epitope)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39BB4SWk0uCL",
        "colab_type": "code",
        "outputId": "8afc13e8-1135-4a8e-9b2d-2efd452a4b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Y_Train.shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50001, 68)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JyrJCzXCY8w",
        "colab_type": "code",
        "outputId": "316f1cf6-e4ec-4b3a-fa5b-f320584624c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "Input_Layer = tf.keras.layers.Input(shape=(22))\n",
        "\n",
        "Embedding_Layer = tf.keras.layers.Embedding(22,4000)(Input_Layer)\n",
        "# LSTM1 = tf.keras.layers.LSTM(400)(Embedding_Layer)\n",
        "\n",
        "Embedding_Layer = tf.keras.layers.Flatten()(Embedding_Layer)\n",
        "\n",
        "# Dense0 = tf.keras.layers.Dense(5000,activation='relu')(Embedding_Layer)\n",
        "Dense1 = tf.keras.layers.Dense(5000,activation='relu')(Embedding_Layer)\n",
        "Dense2 = tf.keras.layers.Dense(5000,activation='relu')(Dense1)\n",
        "Dense3 = tf.keras.layers.Dense(2500)(Dense2)\n",
        "Dense4 = tf.keras.layers.Dense(500)(Dense3) \n",
        "\n",
        "Dense5 = tf.keras.layers.Dense(68, activation='softmax')(Dense4)\n",
        "model = tf.keras.Model(inputs=Input_Layer,outputs=Dense5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCJ0crx6ZhYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "saved = tf.keras.callbacks.ModelCheckpoint(\"/content/TCR_Normal_Model.hdf5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qNs2odwZmHA",
        "colab_type": "code",
        "outputId": "0a0cebc6-c5c4-479d-c0f8-2679ca80cd6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_Train,Y_Train,epochs=200,validation_split=0.2,shuffle=True,callbacks=[saved])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10001 samples\n",
            "Epoch 1/200\n",
            "40000/40000 [==============================] - 59s 1ms/sample - loss: 2.3437 - acc: 0.1937 - val_loss: 6.5089 - val_acc: 0.1234\n",
            "Epoch 2/200\n",
            "40000/40000 [==============================] - 41s 1ms/sample - loss: 2.2650 - acc: 0.2125 - val_loss: 6.7798 - val_acc: 0.1188\n",
            "Epoch 3/200\n",
            "40000/40000 [==============================] - 41s 1ms/sample - loss: 2.2493 - acc: 0.2175 - val_loss: 6.7696 - val_acc: 0.1227\n",
            "Epoch 4/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2391 - acc: 0.2193 - val_loss: 7.2222 - val_acc: 0.1230\n",
            "Epoch 5/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2334 - acc: 0.2212 - val_loss: 6.9800 - val_acc: 0.1205\n",
            "Epoch 6/200\n",
            "40000/40000 [==============================] - 41s 1ms/sample - loss: 2.2283 - acc: 0.2221 - val_loss: 7.1401 - val_acc: 0.1146\n",
            "Epoch 7/200\n",
            "40000/40000 [==============================] - 41s 1ms/sample - loss: 2.2242 - acc: 0.2264 - val_loss: 7.2174 - val_acc: 0.1235\n",
            "Epoch 8/200\n",
            "40000/40000 [==============================] - 41s 1ms/sample - loss: 2.2223 - acc: 0.2244 - val_loss: 7.2859 - val_acc: 0.1215\n",
            "Epoch 9/200\n",
            "40000/40000 [==============================] - 41s 1ms/sample - loss: 2.2197 - acc: 0.2271 - val_loss: 7.0618 - val_acc: 0.1226\n",
            "Epoch 10/200\n",
            "40000/40000 [==============================] - 41s 1ms/sample - loss: 2.2185 - acc: 0.2285 - val_loss: 7.1038 - val_acc: 0.1234\n",
            "Epoch 11/200\n",
            "40000/40000 [==============================] - 41s 1ms/sample - loss: 2.2159 - acc: 0.2277 - val_loss: 7.2132 - val_acc: 0.1201\n",
            "Epoch 12/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2144 - acc: 0.2286 - val_loss: 7.2167 - val_acc: 0.1209\n",
            "Epoch 13/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2129 - acc: 0.2274 - val_loss: 7.3610 - val_acc: 0.1230\n",
            "Epoch 14/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2117 - acc: 0.2305 - val_loss: 7.4450 - val_acc: 0.1197\n",
            "Epoch 15/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2106 - acc: 0.2301 - val_loss: 7.3998 - val_acc: 0.1230\n",
            "Epoch 16/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2100 - acc: 0.2297 - val_loss: 7.3564 - val_acc: 0.1230\n",
            "Epoch 17/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2090 - acc: 0.2299 - val_loss: 7.3850 - val_acc: 0.1235\n",
            "Epoch 18/200\n",
            "40000/40000 [==============================] - 41s 1ms/sample - loss: 2.2081 - acc: 0.2303 - val_loss: 7.3636 - val_acc: 0.1197\n",
            "Epoch 19/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2080 - acc: 0.2292 - val_loss: 7.3773 - val_acc: 0.1204\n",
            "Epoch 20/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2066 - acc: 0.2308 - val_loss: 7.5591 - val_acc: 0.1207\n",
            "Epoch 21/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2058 - acc: 0.2322 - val_loss: 7.7820 - val_acc: 0.1222\n",
            "Epoch 22/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2055 - acc: 0.2312 - val_loss: 7.4703 - val_acc: 0.1228\n",
            "Epoch 23/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2049 - acc: 0.2319 - val_loss: 7.4978 - val_acc: 0.1224\n",
            "Epoch 24/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2040 - acc: 0.2310 - val_loss: 7.6228 - val_acc: 0.1203\n",
            "Epoch 25/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2038 - acc: 0.2331 - val_loss: 7.4889 - val_acc: 0.1211\n",
            "Epoch 26/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2028 - acc: 0.2324 - val_loss: 7.6961 - val_acc: 0.1227\n",
            "Epoch 27/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2028 - acc: 0.2329 - val_loss: 7.5702 - val_acc: 0.1220\n",
            "Epoch 28/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2019 - acc: 0.2324 - val_loss: 7.6138 - val_acc: 0.1231\n",
            "Epoch 29/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2014 - acc: 0.2322 - val_loss: 7.4546 - val_acc: 0.1227\n",
            "Epoch 30/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2011 - acc: 0.2312 - val_loss: 7.8421 - val_acc: 0.1224\n",
            "Epoch 31/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2005 - acc: 0.2330 - val_loss: 7.5894 - val_acc: 0.1207\n",
            "Epoch 32/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2001 - acc: 0.2329 - val_loss: 7.5561 - val_acc: 0.1229\n",
            "Epoch 33/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2003 - acc: 0.2331 - val_loss: 7.6304 - val_acc: 0.1228\n",
            "Epoch 34/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.2002 - acc: 0.2316 - val_loss: 7.5615 - val_acc: 0.1224\n",
            "Epoch 35/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1996 - acc: 0.2343 - val_loss: 7.5516 - val_acc: 0.1239\n",
            "Epoch 36/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1984 - acc: 0.2326 - val_loss: 7.5062 - val_acc: 0.1208\n",
            "Epoch 37/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1985 - acc: 0.2347 - val_loss: 7.7398 - val_acc: 0.1224\n",
            "Epoch 38/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1982 - acc: 0.2336 - val_loss: 7.5245 - val_acc: 0.1225\n",
            "Epoch 39/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1982 - acc: 0.2329 - val_loss: 7.6530 - val_acc: 0.1190\n",
            "Epoch 40/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1977 - acc: 0.2339 - val_loss: 7.6465 - val_acc: 0.1224\n",
            "Epoch 41/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1980 - acc: 0.2309 - val_loss: 7.5874 - val_acc: 0.1209\n",
            "Epoch 42/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1974 - acc: 0.2343 - val_loss: 7.5160 - val_acc: 0.1220\n",
            "Epoch 43/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1975 - acc: 0.2336 - val_loss: 7.6983 - val_acc: 0.1224\n",
            "Epoch 44/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1972 - acc: 0.2343 - val_loss: 7.6408 - val_acc: 0.1205\n",
            "Epoch 45/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1970 - acc: 0.2332 - val_loss: 7.6347 - val_acc: 0.1214\n",
            "Epoch 46/200\n",
            "40000/40000 [==============================] - 41s 1ms/sample - loss: 2.1966 - acc: 0.2342 - val_loss: 7.8451 - val_acc: 0.1223\n",
            "Epoch 47/200\n",
            "40000/40000 [==============================] - 41s 1ms/sample - loss: 2.1967 - acc: 0.2343 - val_loss: 7.8075 - val_acc: 0.1225\n",
            "Epoch 48/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1966 - acc: 0.2335 - val_loss: 7.6613 - val_acc: 0.1206\n",
            "Epoch 49/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1964 - acc: 0.2344 - val_loss: 7.7454 - val_acc: 0.1225\n",
            "Epoch 50/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1957 - acc: 0.2345 - val_loss: 7.8780 - val_acc: 0.1225\n",
            "Epoch 51/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1959 - acc: 0.2338 - val_loss: 7.6911 - val_acc: 0.1225\n",
            "Epoch 52/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1954 - acc: 0.2322 - val_loss: 7.7843 - val_acc: 0.1225\n",
            "Epoch 53/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1955 - acc: 0.2346 - val_loss: 7.7805 - val_acc: 0.1223\n",
            "Epoch 54/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1952 - acc: 0.2340 - val_loss: 7.6439 - val_acc: 0.1214\n",
            "Epoch 55/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1946 - acc: 0.2328 - val_loss: 7.9979 - val_acc: 0.1214\n",
            "Epoch 56/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1949 - acc: 0.2344 - val_loss: 7.9308 - val_acc: 0.1228\n",
            "Epoch 57/200\n",
            "40000/40000 [==============================] - 41s 1ms/sample - loss: 2.1949 - acc: 0.2334 - val_loss: 7.9724 - val_acc: 0.1211\n",
            "Epoch 58/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1940 - acc: 0.2348 - val_loss: 7.9193 - val_acc: 0.1223\n",
            "Epoch 59/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1942 - acc: 0.2353 - val_loss: 7.7819 - val_acc: 0.1200\n",
            "Epoch 60/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1942 - acc: 0.2352 - val_loss: 7.8109 - val_acc: 0.1210\n",
            "Epoch 61/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1936 - acc: 0.2352 - val_loss: 7.7373 - val_acc: 0.1209\n",
            "Epoch 62/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1937 - acc: 0.2341 - val_loss: 7.7617 - val_acc: 0.1223\n",
            "Epoch 63/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1932 - acc: 0.2342 - val_loss: 7.8825 - val_acc: 0.1211\n",
            "Epoch 64/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1936 - acc: 0.2332 - val_loss: 7.8072 - val_acc: 0.1226\n",
            "Epoch 65/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1933 - acc: 0.2340 - val_loss: 7.8801 - val_acc: 0.1211\n",
            "Epoch 66/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1934 - acc: 0.2337 - val_loss: 7.8495 - val_acc: 0.1211\n",
            "Epoch 67/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1930 - acc: 0.2356 - val_loss: 7.9470 - val_acc: 0.1219\n",
            "Epoch 68/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1926 - acc: 0.2348 - val_loss: 7.7411 - val_acc: 0.1189\n",
            "Epoch 69/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1927 - acc: 0.2350 - val_loss: 8.0225 - val_acc: 0.1207\n",
            "Epoch 70/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1925 - acc: 0.2343 - val_loss: 7.9140 - val_acc: 0.1210\n",
            "Epoch 71/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1928 - acc: 0.2352 - val_loss: 8.0417 - val_acc: 0.1201\n",
            "Epoch 72/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1925 - acc: 0.2338 - val_loss: 7.8629 - val_acc: 0.1221\n",
            "Epoch 73/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1919 - acc: 0.2347 - val_loss: 8.0123 - val_acc: 0.1224\n",
            "Epoch 74/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1921 - acc: 0.2344 - val_loss: 7.8972 - val_acc: 0.1203\n",
            "Epoch 75/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1920 - acc: 0.2353 - val_loss: 8.0333 - val_acc: 0.1210\n",
            "Epoch 76/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1924 - acc: 0.2352 - val_loss: 7.9700 - val_acc: 0.1211\n",
            "Epoch 77/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1920 - acc: 0.2344 - val_loss: 7.9122 - val_acc: 0.1209\n",
            "Epoch 78/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1917 - acc: 0.2339 - val_loss: 7.8065 - val_acc: 0.1205\n",
            "Epoch 79/200\n",
            "40000/40000 [==============================] - 41s 1ms/sample - loss: 2.1919 - acc: 0.2334 - val_loss: 7.6735 - val_acc: 0.1206\n",
            "Epoch 80/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1917 - acc: 0.2347 - val_loss: 7.9713 - val_acc: 0.1205\n",
            "Epoch 81/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1915 - acc: 0.2340 - val_loss: 7.8207 - val_acc: 0.1209\n",
            "Epoch 82/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1919 - acc: 0.2345 - val_loss: 7.8079 - val_acc: 0.1205\n",
            "Epoch 83/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1914 - acc: 0.2366 - val_loss: 8.0148 - val_acc: 0.1228\n",
            "Epoch 84/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1913 - acc: 0.2344 - val_loss: 8.0671 - val_acc: 0.1205\n",
            "Epoch 85/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1911 - acc: 0.2333 - val_loss: 8.0640 - val_acc: 0.1208\n",
            "Epoch 86/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1910 - acc: 0.2346 - val_loss: 8.0740 - val_acc: 0.1205\n",
            "Epoch 87/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1911 - acc: 0.2344 - val_loss: 8.1185 - val_acc: 0.1227\n",
            "Epoch 88/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1910 - acc: 0.2347 - val_loss: 7.9401 - val_acc: 0.1211\n",
            "Epoch 89/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1907 - acc: 0.2361 - val_loss: 7.8370 - val_acc: 0.1207\n",
            "Epoch 90/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1905 - acc: 0.2353 - val_loss: 7.9193 - val_acc: 0.1215\n",
            "Epoch 91/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1908 - acc: 0.2348 - val_loss: 7.8413 - val_acc: 0.1207\n",
            "Epoch 92/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1907 - acc: 0.2343 - val_loss: 7.9057 - val_acc: 0.1205\n",
            "Epoch 93/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1904 - acc: 0.2353 - val_loss: 8.1803 - val_acc: 0.1224\n",
            "Epoch 94/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1907 - acc: 0.2358 - val_loss: 8.0420 - val_acc: 0.1211\n",
            "Epoch 95/200\n",
            "40000/40000 [==============================] - 40s 1ms/sample - loss: 2.1905 - acc: 0.2343 - val_loss: 8.0667 - val_acc: 0.1210\n",
            "Epoch 96/200\n",
            "37024/40000 [==========================>...] - ETA: 2s - loss: 2.1915 - acc: 0.2353"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-419509c2a193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_Train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msaved\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.0/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY1FBHSYE44V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/TCR_Model_Normal.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}